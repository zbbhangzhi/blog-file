Paxos实践

Paxos算法为解决数据一致性问题在很多大型分布式系统中都有所应用，如BigTable和HyperTable。

Chubby

BigTable（Google的进行结构化数据存储与管理的大型分布式存储系统）中选用Google Chubby分布式锁服务来解决分布式协作，元数据存储和mater选举等一系列和分布式锁服务有关的问题。

Chubby分为客户端和服务端，客户端面向应用程序，与服务端通信，对服务端的整个文件进行读写操作，或添加对文件的锁控制，并能订阅服务端发出的一系列文件变动的事件通知，根据响应结果控制应用程序是否继续执行。

1. 设计架构

   Chubby提供一个需要访问的中心化节点的分布式锁服务，而不是以算法协议的客户端库的形式存在以便于应用随意调用。

   - 完整独立：算法库是自己维护的，在应用里维护，结构复杂，加大整个系统维护的成本；服务是外部维护只需要访问接口就可以使用功能，侵入性更小
   - 提供粗粒度的锁服务：Chubby面向的场景是客户端一旦获得锁后可以长时间持有，但因如此Chubby需要维护所有锁的持有态。TODO 为什么不用细粒度的锁
   - 便于提供数据的发布和订阅：如在Master选举场景中，需要一种广播机制向所有客户端广播当前的Mater服务器，那么服务器同时也需要提供少量数据存储与读取（客户端通过读取同一个文件）得知Master信息）的功能；如果Master有变化将以事件形式通知所有订阅的客户端；如果使用分布式锁服务来实现可以很方便（因为Master选举就是通过锁服务实现的）而且保证了数据发布订阅和锁服务在分布式上的一致性
   - 提供类似锁接口的服务接口：提供类似的接口降低开发人员学习成本
   - 更便捷的构建更可靠的服务：因为一个分布式一致性算法都是采用投票Quorum机制来进行数据值的选定，而这个投票机制本质就是少数服从多数，整个服务提供的过程需要多台服务器组成一个集群。但是基于对Paxos算法的实现只需要半数以上的机器可用即可，这是它的过半机制。而这个集群的如果要应用的开发人员自己部署，无疑提高了开发成本。

2. 技术架构

    客户端通过RPC调用与服务端通信。Chubby集群（Chubby Cell）由5台服务器组成，这些机器都维护着一份服务端数据库的副本，只有Master才能对数据库进行写操作，其他服务器使用Paxos协议从Master同步数据库的数据以更新。这些机器通过投票的方式过半票选举产生Master，在一段时期（Master租期）内不会有其他机器成为Master。除非Master机器故障，会产生新一轮的选举开始新的租期，不然Master会通过不断续租的方式来延长Master租期。

   客户端与服务端通信过程

   - 客户端定位Master服务器：向存有服务端列表的DNS来请求获取所有服务器列表，逐个询问服务器是否是Master，如果询问到非Master服务器该服务器会主动返回Master服务器标识给客户端
   - 客户端读请求给Master：直接处理，TODO 其他副本服务器什么都不做吗
   - 客户端写请求给Master：一旦Master接受并处理了客户端发送的写请求，Master会用一致性协议将其广播给所有副本服务器，过半服务器接受后再响应给客户端。

   Master服务器故障

   - 集群中的其他服务器会在Master租期到期后重新开启一轮新的选举

   非Master服务器故障

   - 短时间内修复：恢复后自动加入 ，但要先从Master同步更新数据库数据，才能参与Paxos运作中和其他副本服务器一起工作
   - 长时间不可恢复的：加入新的机器并更新DNS列表。因为Master是会周期性的轮询DNS列表，所以它能很快感知到变更，并将集群数据库中的地址列表做变更，其他副本服务器也可以通过**复制**方式拿到最新的服务器列表。 

   目录文件

   - Chubby的数据结构类似一个由文件（文件里有内容）和目录组成的树，数据节点泛指Chubby的文件或目录是Chubby的命名空间，在同一个集群数据库中每个节点都是全局唯一的。
   - 客户端是可以通过自定义的文件系统接口来访问服务端数据
   - 数据节点可分为持久节点和临时节点，持久节点需要接口显式删除，而临时节点随着客户端的会话失效后自动删除，可以作为会话有效性判断的依据
   - 每个数据节点包含少量元数据信息（包含权限控制的访问控制列表ACL），还有4个单调递增的64位编号
     - 实例编号：标识创建改数据节点的顺序
     - 文件内容编号：标识文件内容变化情况
     - 锁编号：标识节点锁变更情况，锁自由free---->锁持有held增加
     - ACL编号：标识节点的ACL信息变更情况

   锁与锁序列器

   为了解决消息的延迟导致的消息重乱序问题（原本先发出的消息因为网络等原因迟迟没到等到了其他的消息已经比它早一步，然后它的操作就把之前那个应该后来的操作覆盖了），Chubb采用锁延迟和锁序列器两种策略解决。

   - 锁延迟：如果客户端因为一些原因短时间和服务器不能通信，但它已经持有了一个锁，那么服务器会为这个客户端对这个锁保留一定的时间，其他客户端暂时不能获取
   - 锁序列器：客户端应用程序在进行一些需要锁机制保护的操作时可以先将锁序列器发给服务端，服务端校验过有效且客户端处于锁模式，那么就可以继续执行，反之就拒绝这个请求

   事件通知机制

   客户端主动向服务器注册事件通知，但这些事件有变更时，服务器会主动通知（异步的）客户端，避免客户端轮询造成一定的资源损耗和服务器压力。常见的事件通知：

   - 文件内容变更：例如写有Master信息的文件如果有变更说明Master机器有变动
   - 节点删除
   - 子节点新增/删除
   - Master服务器转移

   客户端缓存

   为减少客户端频繁对服务器访问，会让客户端缓存一些文件内容和元数据信息

   - 保证缓存和服务器一致性：
     - 租期机制，每个客户端缓存都有一个租期，master会维护每个客户端的缓存，如果有变动就会发送过期信息保证缓存数据的一致性。
     - 如果租期到期，客户端会向服务器发送一个续租维持缓存的有效性。如果文件数据或元数据有变更，服务器会先阻塞这个修改操作，Master先向所有缓存了这个信息的客户端发送缓存过期的信息保证缓存失效，等到Master收到所有针对这个缓存信息的响应（1.要求更新缓存2.允许缓存租期过期）后继续之前的信息修改操作。
     - <u>TODO</u> 客户端不答应还能咋，减少频繁访问的压力和频繁更新缓存信息并保证强一致性这之间浪费的开销不相上下吧

   会话和会话激活

   客户端和服务端通过TCP连接通信，这个连接叫做会话session，为了使会话在超时时间内长时间延续活性，客户端会定时向服务端发送心跳，这个过程叫会话激活keepalive，那客户端创建句柄，锁和缓存数据等依旧有效。

   - 服务端接收到客户端的KeepAlive请求，先将请求阻塞，等到客户端当前的会话租期就要过期，才续租这个会话租期（默认12s）；然后再响应这个KeepAlive请求，并将最新的会话租期超时时间反馈给客户端。TODO 这个阻塞是怎样的
   - 如果当前服务端处于高负载的情况，会延长会话租期，减少KeepAlive请求。
   - 客户端在收到续租响应后会再发一个新的KeepAlive请求，Master会阻塞它。因为续租时间不长所以一直在请求延长，直到它主动关闭会话

   会话超时

   服务端是主要维护会话租期的，客户端自身也会维护一个类似的，因为请求响应来回费了不少时间所以这个租期不是很准。但是如果客户端自身知道会话就要过期了：

   - jeopardy：Master还没反馈KeepAlive的响应，客户端向应用程序发送jeopardy事件通知等待。那这个时候客户端就会清空本地缓存并标记自身为不可用，
   - safe：等待宽限期45s内，如果成功和服务端进行KeepAlive就会再次开启本地缓存，客户端以safe事件通知应用程序可以 继续正常执行。
   - expired：等待宽限期45s后，没有正常恢复就会终止此次和服务端的会话，并向应用程序发送expired事件通知会话超时，因为Chubby服务不可用那么应用程序将会重启（TODO重启换个连？？？）。

   ***Master故障及修复***

3. Paxos协议实现

   Chubby服务端的基本架构

   - 最底层-容错日志系统：通过Paxos保证集群里所有机器日志完全一致，并有较好的容错性
   - 中层-容错数据库：通过底层的日志系统保证一致性和容错性，初版Chubby使用了具有数据复制特性的Berkely DB，但后来避免因引入外来组件带来的风险和依赖改为自己实现一个简单的底层数据复制组件--基于日志预写和数据快照（定期对状态数据做数据快照并存入磁盘）技术，如果副本宕机且存快照的磁盘损坏就会直接向其他副本索要全部状态数据，如果磁盘没坏就自己主动本地快照恢复，磁盘上某时间点后没有的数据也向其他副本索取。为了安全起见，宕机的副本会等到它之前检测到的最大并发提案数量都执行完才开始参与提案选择。TODO 这里宕机重启不理解为什么要等待
   - 高层-对外提供的分布式锁服务和小文件存储服务

以日志中的日志记录为例，每条记录对于Paxos算法中的一个Instance，每个Instance有唯一的Instance编号。每个日志副本Instance的选定过程需要通过执行Promis-->Accept，如果Master接收到多数派的Accept反馈后，将这个Instance编号写入本地事务日志并广播commit消息给集群中的其他副本节点，其他的副本收到也会写入到他们的事务日志中，如果某个副本没有收到就会主动从其他副本节点查询。